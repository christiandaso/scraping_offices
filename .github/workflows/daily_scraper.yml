name: Daily Scraper

# 1Ô∏è‚É£ Programaci√≥n: todos los d√≠as a las 01:00 UTC (‚Üí 20:00 Per√∫)
# 2Ô∏è‚É£ Manual: workflow_dispatch
on:
  schedule:
    - cron: '30 2 * * *'
  workflow_dispatch:

# Necesitamos permiso de escritura en el repo para hacer push
permissions:
  contents: write

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
      # Paso 1: bajar el c√≥digo
      - name: Clonar el repositorio
        uses: actions/checkout@v3
        with:
          persist-credentials: true   # Importante para poder hacer push

      # Paso 2: configurar Python
      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # Paso 3: instalar dependencias
      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas

      # Paso 4: ejecutar tu script
      - name: Ejecutar script
        run: python ETL.py

      # Paso 5: a√±adir, commitear y pushear el CSV generado
      - name: Commit and push CSV
        run: |
          # Configura un autor para el commit
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # A√±ade cambios (la carpeta Data) y commitea, si hay algo nuevo
          git add Data/data_consultorios_*.csv
          git diff --cached --quiet || git commit -m "üîÑ Actualiza CSV de consultorios: $(date +'%Y-%m-%d')"

          # Empuja al repo
          git push
